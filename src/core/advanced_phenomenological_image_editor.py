"""
Advanced Phenomenological Image Editor - é«˜åº¦ç¾è±¡å­¦çš„ç”»åƒç·¨é›†ã‚·ã‚¹ãƒ†ãƒ 
27ãƒãƒ¼ãƒ‰å°‚ç”¨ã‚¨ãƒ•ã‚§ã‚¯ãƒˆã‚·ã‚¹ãƒ†ãƒ ã®ãƒ¡ã‚¤ãƒ³ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹
"""

import numpy as np
from PIL import Image
from typing import Dict, List, Tuple, Any, Optional, Union
from dataclasses import dataclass
import json
from pathlib import Path
import time
from datetime import datetime

try:
    from .phenomenological_compositor import PhenomenologicalCompositor
    from .node_effect_mapper import NodeEffectMapper, EffectParameters
    from .appearance_effects import AppearanceEffects
except ImportError:
    from phenomenological_compositor import PhenomenologicalCompositor
    from node_effect_mapper import NodeEffectMapper, EffectParameters
    from appearance_effects import AppearanceEffects


@dataclass
class EditingSession:
    """ç·¨é›†ã‚»ãƒƒã‚·ãƒ§ãƒ³ã®æƒ…å ±"""
    session_id: str
    start_time: datetime
    original_image_size: Tuple[int, int]
    node_states_history: List[Dict[str, float]]
    effects_applied: List[str]
    composition_mode: str
    total_processing_time: float = 0.0


class AdvancedPhenomenologicalImageEditor:
    """
    é«˜åº¦ç¾è±¡å­¦çš„ç”»åƒç·¨é›†ã‚·ã‚¹ãƒ†ãƒ 
    27ãƒãƒ¼ãƒ‰çŠ¶æ…‹å€¤ã«åŸºã¥ãå“²å­¦çš„ã«å³å¯†ãªç”»åƒã‚¨ãƒ•ã‚§ã‚¯ãƒˆå‡¦ç†
    """
    
    def __init__(self, connectivity_matrix: Optional[np.ndarray] = None,
                 node_list: Optional[List[str]] = None):
        """
        åˆæœŸåŒ–
        
        Args:
            connectivity_matrix: ãƒãƒ¼ãƒ‰é–“æ¥ç¶šè¡Œåˆ—
            node_list: ãƒãƒ¼ãƒ‰åã®ãƒªã‚¹ãƒˆ
        """
        self.compositor = PhenomenologicalCompositor(connectivity_matrix, node_list)
        self.node_mapper = self.compositor.node_mapper
        
        # ã‚»ãƒƒã‚·ãƒ§ãƒ³ç®¡ç†
        self.current_session: Optional[EditingSession] = None
        self.session_history: List[EditingSession] = []
        
        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥è¨­å®š
        self.enable_caching = True
        self.effect_cache: Dict[str, Image.Image] = {}
        
        # ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰
        self.debug_mode = False
        
    def start_editing_session(self, image: Image.Image, session_id: str = None) -> str:
        """
        ç·¨é›†ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’é–‹å§‹
        
        Args:
            image: ç·¨é›†å¯¾è±¡ç”»åƒ
            session_id: ã‚»ãƒƒã‚·ãƒ§ãƒ³IDï¼ˆæŒ‡å®šã—ãªã„å ´åˆã¯è‡ªå‹•ç”Ÿæˆï¼‰
            
        Returns:
            ã‚»ãƒƒã‚·ãƒ§ãƒ³ID
        """
        if session_id is None:
            session_id = f"session_{int(time.time())}"
            
        self.current_session = EditingSession(
            session_id=session_id,
            start_time=datetime.now(),
            original_image_size=(image.width, image.height),
            node_states_history=[],
            effects_applied=[],
            composition_mode="layered"
        )
        
        if self.debug_mode:
            print(f"ğŸ“¸ Started editing session: {session_id}")
            print(f"   Image size: {image.width}x{image.height}")
            
        return session_id
    
    def apply_phenomenological_transformation(self, 
                                           image: Image.Image,
                                           node_states: Dict[str, float],
                                           composition_mode: str = "layered",
                                           enable_interaction: bool = True) -> Image.Image:
        """
        ç¾è±¡å­¦çš„å¤‰æ›ã®é©ç”¨
        
        Args:
            image: å…¥åŠ›ç”»åƒ
            node_states: 27ãƒãƒ¼ãƒ‰ã®çŠ¶æ…‹å€¤
            composition_mode: åˆæˆãƒ¢ãƒ¼ãƒ‰ ("layered", "sequential", "parallel")
            enable_interaction: ãƒãƒ¼ãƒ‰é–“ç›¸äº’ä½œç”¨ã®æœ‰åŠ¹åŒ–
            
        Returns:
            å¤‰æ›ã•ã‚ŒãŸç”»åƒ
        """
        start_time = time.time()
        
        # ã‚»ãƒƒã‚·ãƒ§ãƒ³æƒ…å ±ã®æ›´æ–°
        if self.current_session:
            self.current_session.node_states_history.append(node_states.copy())
            self.current_session.composition_mode = composition_mode
        
        try:
            # ãƒãƒ¼ãƒ‰çŠ¶æ…‹ã®æ¤œè¨¼
            validation_errors = self.node_mapper.validate_node_states(node_states)
            if validation_errors:
                raise ValueError(f"Node validation failed: {validation_errors}")
            
            # ç¾è±¡å­¦çš„åˆæˆã®å®Ÿè¡Œ
            if enable_interaction:
                result_image = self.compositor.compose_phenomenological_image(
                    image, node_states, composition_mode
                )
            else:
                # ç›¸äº’ä½œç”¨ãªã—ã®å˜ç´”é©ç”¨
                result_image = self._apply_effects_without_interaction(
                    image, node_states
                )
            
            # å‡¦ç†æ™‚é–“ã®è¨˜éŒ²
            processing_time = time.time() - start_time
            if self.current_session:
                self.current_session.total_processing_time += processing_time
                
            if self.debug_mode:
                print(f"âš¡ Phenomenological transformation completed in {processing_time:.3f}s")
                active_nodes = [k for k, v in node_states.items() if v > 0.1]
                print(f"   Active nodes ({len(active_nodes)}): {active_nodes[:5]}{'...' if len(active_nodes) > 5 else ''}")
                
            return result_image
            
        except Exception as e:
            if self.debug_mode:
                print(f"âŒ Transformation failed: {e}")
            raise
    
    def _apply_effects_without_interaction(self, image: Image.Image,
                                         node_states: Dict[str, float]) -> Image.Image:
        """ç›¸äº’ä½œç”¨ãªã—ã§ã‚¨ãƒ•ã‚§ã‚¯ãƒˆã‚’é©ç”¨"""
        effect_params = self.node_mapper.map_node_states_to_effects(node_states)
        
        if not effect_params:
            return image
            
        current_image = image
        
        # ç¾åœ¨å®Ÿè£…ã•ã‚Œã¦ã„ã‚‹ã‚¨ãƒ•ã‚§ã‚¯ãƒˆã®ã¿é©ç”¨
        for param in effect_params:
            if param.effect_name in ["density_effect", "luminosity_effect", "chromaticity_effect"]:
                try:
                    if param.effect_name == "density_effect":
                        current_image = AppearanceEffects.density_effect(
                            current_image, param.intensity, param.node_state
                        )
                    elif param.effect_name == "luminosity_effect":
                        current_image = AppearanceEffects.luminosity_effect(
                            current_image, param.intensity, param.node_state
                        )
                    elif param.effect_name == "chromaticity_effect":
                        current_image = AppearanceEffects.chromaticity_effect(
                            current_image, param.intensity, param.node_state
                        )
                        
                    if self.current_session:
                        self.current_session.effects_applied.append(param.effect_name)
                        
                except Exception as e:
                    if self.debug_mode:
                        print(f"Warning: Failed to apply {param.effect_name}: {e}")
                    continue
        
        return current_image
    
    def apply_dimensional_focus(self, image: Image.Image,
                              node_states: Dict[str, float],
                              target_dimension: str,
                              focus_intensity: float = 0.8) -> Image.Image:
        """
        ç‰¹å®šæ¬¡å…ƒã¸ã®é›†ä¸­ã‚¨ãƒ•ã‚§ã‚¯ãƒˆ
        
        Args:
            image: å…¥åŠ›ç”»åƒ
            node_states: ãƒãƒ¼ãƒ‰çŠ¶æ…‹å€¤
            target_dimension: å¯¾è±¡æ¬¡å…ƒ ("appearance", "intentional", etc.)
            focus_intensity: é›†ä¸­å¼·åº¦
            
        Returns:
            æ¬¡å…ƒé›†ä¸­ã‚¨ãƒ•ã‚§ã‚¯ãƒˆãŒé©ç”¨ã•ã‚ŒãŸç”»åƒ
        """
        # å¯¾è±¡æ¬¡å…ƒã®ãƒãƒ¼ãƒ‰ã®ã¿ã‚’å¼·èª¿
        focused_states = {}
        
        for node_name, value in node_states.items():
            if node_name.startswith(target_dimension + "_"):
                # å¯¾è±¡æ¬¡å…ƒã®ãƒãƒ¼ãƒ‰ã‚’å¼·èª¿
                focused_states[node_name] = min(1.0, value * (1 + focus_intensity))
            else:
                # ãã®ä»–ã®ãƒãƒ¼ãƒ‰ã‚’æŠ‘åˆ¶
                focused_states[node_name] = value * (1 - focus_intensity * 0.5)
        
        return self.apply_phenomenological_transformation(
            image, focused_states, "layered", True
        )
    
    def create_phenomenological_blend(self, images: List[Image.Image],
                                    node_states_list: List[Dict[str, float]],
                                    blend_weights: Optional[List[float]] = None) -> Image.Image:
        """
        è¤‡æ•°ç”»åƒã®ç¾è±¡å­¦çš„ãƒ–ãƒ¬ãƒ³ãƒ‰
        
        Args:
            images: å…¥åŠ›ç”»åƒãƒªã‚¹ãƒˆ
            node_states_list: å„ç”»åƒã®ãƒãƒ¼ãƒ‰çŠ¶æ…‹å€¤ãƒªã‚¹ãƒˆ
            blend_weights: ãƒ–ãƒ¬ãƒ³ãƒ‰é‡ã¿ï¼ˆçœç•¥æ™‚ã¯å‡ç­‰ï¼‰
            
        Returns:
            ãƒ–ãƒ¬ãƒ³ãƒ‰ã•ã‚ŒãŸç”»åƒ
        """
        if len(images) != len(node_states_list):
            raise ValueError("Images and node_states_list must have same length")
        
        if blend_weights is None:
            blend_weights = [1.0 / len(images)] * len(images)
        elif len(blend_weights) != len(images):
            raise ValueError("Blend weights must match number of images")
        
        # å„ç”»åƒã«ç¾è±¡å­¦çš„å¤‰æ›ã‚’é©ç”¨
        transformed_images = []
        for image, node_states in zip(images, node_states_list):
            transformed = self.apply_phenomenological_transformation(
                image, node_states, "parallel", True
            )
            transformed_images.append(transformed)
        
        # é‡ã¿ä»˜ããƒ–ãƒ¬ãƒ³ãƒ‰
        return self._weighted_blend_images(transformed_images, blend_weights)
    
    def _weighted_blend_images(self, images: List[Image.Image], 
                              weights: List[float]) -> Image.Image:
        """é‡ã¿ä»˜ãç”»åƒãƒ–ãƒ¬ãƒ³ãƒ‰"""
        # é‡ã¿ã®æ­£è¦åŒ–
        total_weight = sum(weights)
        normalized_weights = [w / total_weight for w in weights]
        
        # æœ€åˆã®ç”»åƒã‚’ãƒ™ãƒ¼ã‚¹ã«è¨­å®š
        base_array = np.array(images[0]).astype(np.float32) * normalized_weights[0]
        
        # æ®‹ã‚Šã®ç”»åƒã‚’é‡ã¿ä»˜ãã§åŠ ç®—
        for image, weight in zip(images[1:], normalized_weights[1:]):
            image_array = np.array(image).astype(np.float32)
            base_array += image_array * weight
        
        result_array = np.clip(base_array, 0, 255).astype(np.uint8)
        return Image.fromarray(result_array)
    
    def analyze_phenomenological_state(self, node_states: Dict[str, float]) -> Dict[str, Any]:
        """
        ç¾è±¡å­¦çš„çŠ¶æ…‹ã®åˆ†æ
        
        Args:
            node_states: ãƒãƒ¼ãƒ‰çŠ¶æ…‹å€¤
            
        Returns:
            åˆ†æçµæœ
        """
        analysis = {
            "dimensional_analysis": {},
            "dominant_nodes": [],
            "philosophical_interpretation": {},
            "recommended_effects": []
        }
        
        # æ¬¡å…ƒåˆ¥åˆ†æ
        dimensions = ["appearance", "intentional", "temporal", "synesthetic", 
                     "ontological", "semantic", "conceptual", "being", "certainty"]
        
        for dimension in dimensions:
            dim_nodes = [k for k in node_states.keys() if k.startswith(dimension + "_")]
            if dim_nodes:
                dim_values = [node_states[k] for k in dim_nodes]
                analysis["dimensional_analysis"][dimension] = {
                    "average": np.mean(dim_values),
                    "max": np.max(dim_values),
                    "dominant_node": dim_nodes[np.argmax(dim_values)],
                    "activity_level": "high" if np.mean(dim_values) > 0.6 else "medium" if np.mean(dim_values) > 0.3 else "low"
                }
        
        # æ”¯é…çš„ãƒãƒ¼ãƒ‰ã®ç‰¹å®š
        sorted_nodes = sorted(node_states.items(), key=lambda x: x[1], reverse=True)
        analysis["dominant_nodes"] = sorted_nodes[:5]  # ä¸Šä½5ãƒãƒ¼ãƒ‰
        
        # å“²å­¦çš„è§£é‡ˆ
        analysis["philosophical_interpretation"] = self._generate_philosophical_interpretation(node_states)
        
        # æ¨å¥¨ã‚¨ãƒ•ã‚§ã‚¯ãƒˆ
        effect_params = self.node_mapper.map_node_states_to_effects(node_states)
        analysis["recommended_effects"] = [
            {"effect": p.effect_name, "intensity": p.intensity, "node": p.node_state}
            for p in effect_params[:3]  # ä¸Šä½3ã¤
        ]
        
        return analysis
    
    def _generate_philosophical_interpretation(self, node_states: Dict[str, float]) -> Dict[str, str]:
        """å“²å­¦çš„è§£é‡ˆã®ç”Ÿæˆ"""
        interpretation = {}
        
        # ç¾å‡ºæ§˜å¼ã®è§£é‡ˆ
        appearance_avg = np.mean([v for k, v in node_states.items() if k.startswith("appearance_")])
        if appearance_avg > 0.7:
            interpretation["appearance"] = "é«˜åº¦ãªç¾è±¡å­¦çš„å……å®Ÿ - æ„è­˜ã®å¿—å‘çš„ä½œç”¨ãŒå¼·ãé›†ä¸­ã—ã¦ã„ã‚‹çŠ¶æ…‹"
        elif appearance_avg > 0.4:
            interpretation["appearance"] = "ä¸­ç¨‹åº¦ã®ç¾å‡º - ãƒãƒ©ãƒ³ã‚¹ã®å–ã‚ŒãŸç¾è±¡å­¦çš„ç¾ã‚Œ"
        else:
            interpretation["appearance"] = "ä½ã„ç¾å‡ºåº¦ - åœ°å¹³çš„èƒŒæ™¯ã¸ã®æ²ˆé™å‚¾å‘"
        
        # å­˜åœ¨è«–çš„è§£é‡ˆ
        ontological_avg = np.mean([v for k, v in node_states.items() if k.startswith("ontological_")])
        if ontological_avg > 0.6:
            interpretation["ontological"] = "å¼·ã„å­˜åœ¨è«–çš„å¯†åº¦ - å­˜åœ¨è€…ã®æ˜ç¢ºãªç¾å‰æ€§"
        else:
            interpretation["ontological"] = "å­˜åœ¨è«–çš„å¸Œè–„åŒ– - å­˜åœ¨å¿˜å´ã®å‚¾å‘"
        
        # æ™‚é–“çš„è§£é‡ˆ  
        temporal_avg = np.mean([v for k, v in node_states.items() if k.startswith("temporal_")])
        if node_states.get("temporal_decay", 0) > 0.5:
            interpretation["temporal"] = "é ½è½çš„æ™‚é–“æ€§ - ãƒã‚¤ãƒ‡ã‚¬ãƒ¼çš„ãªéæœ¬æ¥çš„æ™‚é–“ã¸ã®æ²ˆé™"
        elif temporal_avg > 0.5:
            interpretation["temporal"] = "å‹•çš„æ™‚é–“æ€§ - ç”Ÿãã‚‰ã‚ŒãŸæ™‚é–“ã®æ´»æ€§åŒ–"
        else:
            interpretation["temporal"] = "é™çš„æ™‚é–“æ€§ - æ™‚é–“æ„è­˜ã®ä½ä¸‹"
        
        return interpretation
    
    def finish_editing_session(self) -> Optional[EditingSession]:
        """ç·¨é›†ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’çµ‚äº†"""
        if self.current_session is None:
            return None
            
        finished_session = self.current_session
        self.session_history.append(finished_session)
        self.current_session = None
        
        if self.debug_mode:
            print(f"ğŸ“‹ Finished session: {finished_session.session_id}")
            print(f"   Total effects applied: {len(finished_session.effects_applied)}")
            print(f"   Total processing time: {finished_session.total_processing_time:.3f}s")
            
        return finished_session
    
    def get_session_statistics(self) -> Dict[str, Any]:
        """ã‚»ãƒƒã‚·ãƒ§ãƒ³çµ±è¨ˆã®å–å¾—"""
        if not self.session_history:
            return {"message": "No completed sessions"}
        
        total_sessions = len(self.session_history)
        total_effects = sum(len(s.effects_applied) for s in self.session_history)
        total_time = sum(s.total_processing_time for s in self.session_history)
        avg_time_per_session = total_time / total_sessions
        
        # æœ€ã‚‚ä½¿ç”¨ã•ã‚ŒãŸã‚¨ãƒ•ã‚§ã‚¯ãƒˆ
        all_effects = []
        for session in self.session_history:
            all_effects.extend(session.effects_applied)
        
        from collections import Counter
        effect_counts = Counter(all_effects)
        most_used_effects = effect_counts.most_common(5)
        
        return {
            "total_sessions": total_sessions,
            "total_effects_applied": total_effects,
            "total_processing_time": f"{total_time:.3f}s",
            "average_time_per_session": f"{avg_time_per_session:.3f}s",
            "most_used_effects": most_used_effects,
            "average_effects_per_session": total_effects / total_sessions if total_sessions > 0 else 0
        }
    
    def export_session_data(self, filepath: str, include_node_states: bool = True):
        """ã‚»ãƒƒã‚·ãƒ§ãƒ³ãƒ‡ãƒ¼ã‚¿ã®ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ"""
        export_data = {
            "export_timestamp": datetime.now().isoformat(),
            "total_sessions": len(self.session_history),
            "sessions": []
        }
        
        for session in self.session_history:
            session_data = {
                "session_id": session.session_id,
                "start_time": session.start_time.isoformat(),
                "original_image_size": session.original_image_size,
                "effects_applied": session.effects_applied,
                "composition_mode": session.composition_mode,
                "total_processing_time": session.total_processing_time
            }
            
            if include_node_states:
                session_data["node_states_history"] = session.node_states_history
                
            export_data["sessions"].append(session_data)
        
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(export_data, f, indent=2, ensure_ascii=False)
            
        if self.debug_mode:
            print(f"ğŸ“ Session data exported to: {filepath}")
    
    def set_debug_mode(self, enabled: bool):
        """ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰ã®è¨­å®š"""
        self.debug_mode = enabled
        self.compositor.debug_mode = enabled if hasattr(self.compositor, 'debug_mode') else False
        
    def clear_cache(self):
        """ã‚¨ãƒ•ã‚§ã‚¯ãƒˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ã®ã‚¯ãƒªã‚¢"""
        self.effect_cache.clear()
        if self.debug_mode:
            print("ğŸ§¹ Effect cache cleared")